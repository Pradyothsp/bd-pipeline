{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "afF4NW690oTM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, col, count, desc, max, min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/11/14 00:05:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "auwWspQl01g3"
      },
      "outputs": [],
      "source": [
        "orc_data = spark.read.format(\"orc\").load(\"kafka_output/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp8cEv8r06vY"
      },
      "source": [
        "# 1) Product Analysis: Group and analyze products by category, brand, and price range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hneZ88Wi0389",
        "outputId": "fc05351a-731c-4eb5-d743-c0302abdf20c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenJDK 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
            "OpenJDK 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodeCache: size=131072Kb used=19301Kb max_used=19309Kb free=111770Kb\n",
            " bounds [0x000000010898c000, 0x0000000109c7c000, 0x000000011098c000]\n",
            " total_blobs=8447 nmethods=7559 adapters=801\n",
            " compilation: disabled (not enough contiguous free space left)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------+------------------+\n",
            "|       category_code|   brand|        avg(price)|\n",
            "+--------------------+--------+------------------+\n",
            "|electronics.smart...|    oppo| 302.8888324460261|\n",
            "|                    |      ea| 68.92890645906827|\n",
            "|       kids.carriage|  babyzz|225.46380384360455|\n",
            "|                    |  veston| 36.77804644412188|\n",
            "|                    |  maxler| 24.79519963104494|\n",
            "|                    |bioderma|16.030129462849782|\n",
            "|appliances.kitche...|   flama| 89.06770224988001|\n",
            "|                    | dynamic|103.56231522271145|\n",
            "|furniture.bedroom...|stolplit| 229.0481719316426|\n",
            "|appliances.enviro...| airline| 57.05532041728795|\n",
            "+--------------------+--------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "product_analysis = orc_data.groupby('category_code', 'brand').agg({'price': 'avg'})\n",
        "product_analysis.show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZM7HhXY09mX"
      },
      "source": [
        "# 2)User Behavior Analysis: Investigate user sessions, their interactions, and behavior based on the events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhfBPowE1Aye",
        "outputId": "55340d4c-4550-46fd-e904-7f0f91f0fc3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 8:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|        user_session|count|\n",
            "+--------------------+-----+\n",
            "|85b88520-d38c-412...|    2|\n",
            "|6e8ae906-2f71-41f...|    7|\n",
            "|a1c24cac-d045-44e...|    4|\n",
            "|65122323-c58f-467...|    4|\n",
            "|a142e90d-f9ae-474...|   26|\n",
            "|ad7c854e-e44d-4cc...|    8|\n",
            "|2ee1b9b2-17c3-432...|   10|\n",
            "|c7ed7188-c559-419...|   37|\n",
            "|85f7ff08-861a-47c...|    7|\n",
            "|429e917d-a4d5-423...|    6|\n",
            "|cd49f84a-8eae-467...|   70|\n",
            "|977e3feb-e0d9-499...|   22|\n",
            "|052afb03-4470-4b1...|    3|\n",
            "|61c4e2a4-1ab1-4ac...|    2|\n",
            "|b930492f-ec5a-479...|    1|\n",
            "|2a4a0103-62db-482...|    1|\n",
            "|b73680a2-38e0-4f5...|    3|\n",
            "|8c7490ff-8405-499...|    3|\n",
            "|3ba9c2dd-800d-45a...|   44|\n",
            "|2d7ade65-1d4b-455...|    5|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "user_behavior = orc_data.groupBy('user_session').count()\n",
        "\n",
        "# Displaying user behavior based on events\n",
        "user_behavior.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqX4wRG1DEK"
      },
      "source": [
        "# 3)Pricing Trends: Identify pricing trends over the 'event_time' for various products or categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuS4jEWb1Gxk",
        "outputId": "47bb944d-e970-4d18-a258-3863dc839fef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 11:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+------------------+\n",
            "|         event_time|       category_code|        avg(price)|\n",
            "+-------------------+--------------------+------------------+\n",
            "|2019-09-30 20:00:00|appliances.enviro...|              33.2|\n",
            "|2019-09-30 20:00:17|                    |            357.79|\n",
            "|2019-09-30 20:00:18|electronics.video.tv|            193.03|\n",
            "|2019-09-30 20:00:42|electronics.audio...|             33.21|\n",
            "|2019-09-30 20:01:05|  computers.notebook|           1512.78|\n",
            "|2019-09-30 20:01:43|appliances.enviro...|             90.07|\n",
            "|2019-09-30 20:04:14|electronics.smart...|            975.57|\n",
            "|2019-09-30 20:04:23|construction.tool...|              48.9|\n",
            "|2019-09-30 20:05:07|                    |             86.21|\n",
            "|2019-09-30 20:05:38|                    |             66.29|\n",
            "|2019-09-30 20:06:20|  electronics.clocks|            133.85|\n",
            "|2019-09-30 20:06:49|                    |            669.23|\n",
            "|2019-09-30 20:06:54|electronics.smart...|396.38000000000005|\n",
            "|2019-09-30 20:07:11|  apparel.shoes.keds|             66.67|\n",
            "|2019-09-30 20:08:07|electronics.smart...|            975.57|\n",
            "|2019-09-30 20:08:13|appliances.kitche...|             69.24|\n",
            "|2019-09-30 20:08:57|electronics.smart...|            711.59|\n",
            "|2019-09-30 20:10:04|appliances.kitche...|            295.49|\n",
            "|2019-09-30 20:10:51|appliances.kitche...|            100.38|\n",
            "|2019-09-30 20:11:22|                    |            297.05|\n",
            "+-------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Convert 'event_time' to a timestamp format\n",
        "orc_data = orc_data.withColumn('event_time', col('event_time').cast('timestamp'))\n",
        "\n",
        "# Grouping by time and category to observe price trends\n",
        "price_trends = orc_data.groupBy('event_time', 'category_code').agg({'price': 'avg'})\n",
        "\n",
        "# Displaying price trends over time for various categories\n",
        "price_trends.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRzdvDww1J0u"
      },
      "source": [
        "# 4)Event Type Frequency: Determine the frequency of different event types (e.g., 'view', 'click', 'purchase')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fir0mC2N1MEH",
        "outputId": "6edf692b-4e2d-4f3b-a6d9-042ab62d327e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 12:=====================================================>(772 + 8) / 783]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|event_type|    count|\n",
            "+----------+---------+\n",
            "|  purchase|  1715406|\n",
            "|      view|107676357|\n",
            "|      cart|  4003978|\n",
            "+----------+---------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "event_frequency = orc_data.groupBy('event_type').count()\n",
        "\n",
        "# Displaying frequency of different event types\n",
        "event_frequency.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fyWt5cVJ_yaN"
      },
      "outputs": [],
      "source": [
        "cleaned_data = orc_data.na.drop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1a1lUio_uhX"
      },
      "source": [
        "### Printing top category_brand combination for each user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 0:>                                                        (0 + 8) / 783]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodeCache: size=131072Kb used=20129Kb max_used=20162Kb free=110942Kb\n",
            " bounds [0x000000010918c000, 0x000000010a56c000, 0x000000011118c000]\n",
            " total_blobs=8554 nmethods=7664 adapters=805\n",
            " compilation: disabled (not enough contiguous free space left)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenJDK 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
            "OpenJDK 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n",
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/11/14 07:07:38 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 998202 ms exceeds timeout 120000 ms\n",
            "23/11/14 07:07:38 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
            "23/11/14 07:21:54 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:21:54 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:52:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:54:13 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 07:54:13 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 08:22:55 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 08:22:55 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 08:40:08 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 08:40:08 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:00:00 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:00:00 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:02:33 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:02:33 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:02:43 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 09:02:43 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 09:02:53 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:02:53 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:36 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:36 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:46 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:46 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:56 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 09:05:56 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:00 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:00 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:08 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:08 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:18 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:18:18 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:23:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:23:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:23:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:23:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:24:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:25:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:26:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:26:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:27:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:27:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:27:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:28:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:28:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:28:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:28:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:28:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:28:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:29:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:29:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
            "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
            "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
            "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
            "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
            "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
            "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
            "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
            "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
            "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
            "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
            "\t... 8 more\n",
            "23/11/14 10:29:51 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:29:51 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:01 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:01 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:11 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:11 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:21 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:21 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:31 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:31 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:41 ERROR Inbox: Ignoring error\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:41 WARN Executor: Issue communicating with driver in heartbeater\n",
            "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
            "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
            "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
            "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
            "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
            "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
            "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
            "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
            "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
            "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
            "\tat java.lang.Thread.run(Thread.java:750)\n",
            "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
            "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
            "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
            "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
            "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
            "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
            "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
            "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
            "\t... 3 more\n",
            "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@134.88.143.56:57435\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
            "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
            "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
            "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
            "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
            "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
            "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
            "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
            "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
            "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
            "\t... 17 more\n",
            "23/11/14 10:30:41 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import desc, col\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"user_category_interaction\").getOrCreate()\n",
        "\n",
        "# Assuming 'cleaned_data' is your existing Spark DataFrame\n",
        "\n",
        "# Group by 'user_id', 'category_code', count interactions\n",
        "user_category_interaction_count = cleaned_data.groupBy('user_id', 'category_code').count()\n",
        "\n",
        "# Sort by count in descending order\n",
        "user_category_interaction_count = user_category_interaction_count.orderBy(desc('count'))\n",
        "\n",
        "# Collect the top 10 interactions\n",
        "top_10_interactions = user_category_interaction_count.limit(10)\n",
        "\n",
        "# Save the top 10 interactions to CSV format\n",
        "# top_10_interactions.to_csv('spark_output/top_10_interactions.csv', index=False)\n",
        "\n",
        "# Plotting the top 10 user interactions\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Group by 'category_code', collect counts, and plot\n",
        "category_counts = top_10_interactions.groupBy('category_code').agg({'count': 'collect_list'}).collect()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for category in category_counts:\n",
        "    category_code = category['category_code']\n",
        "    counts = category['collect_list(count)']\n",
        "    plt.bar([str(i) for i in range(len(counts))], counts, label=category_code)\n",
        "\n",
        "plt.xlabel('User ID')\n",
        "plt.ylabel('Count')\n",
        "plt.title('User Interaction Counts for Top 10 Categories')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Collect the top 10 interactions\n",
        "top_10_interactions = top_10_interactions.toPandas()\n",
        "\n",
        "# Save the top 10 interactions to CSV format\n",
        "top_10_interactions.to_csv('spark_output/top_10_interactions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['kids.carriage',\n",
              " '',\n",
              " 'electronics.smartphone',\n",
              " 'electronics.smartphone',\n",
              " 'kids.carriage',\n",
              " '',\n",
              " 'electronics.smartphone',\n",
              " 'electronics.smartphone',\n",
              " 'auto.accessories.player',\n",
              " '']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ignore = list(top_10_interactions['category_code'])\n",
        "ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g68R7AVAEHjH"
      },
      "source": [
        "### Most Engaged Users within Categories and Brands:\n",
        "Identify users who interact the most with specific categories or brands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mUeGUFn8-GI",
        "outputId": "5d979778-59e5-4df6-b085-ee90c44cc960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/11/13 21:44:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:48:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:49:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:50:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------+---------+---------+\n",
            "|       category_code|  brand|  user_id|max_count|\n",
            "+--------------------+-------+---------+---------+\n",
            "|electronics.smart...|samsung|513805641|     5597|\n",
            "|electronics.smart...|samsung|548680744|     5597|\n",
            "|electronics.smart...|samsung|559687595|     5597|\n",
            "|electronics.smart...|samsung|555271034|     5597|\n",
            "|electronics.smart...|samsung|514652411|     5597|\n",
            "|electronics.smart...|samsung|549264178|     5597|\n",
            "|electronics.smart...|samsung|518873554|     5597|\n",
            "|electronics.smart...|samsung|513115532|     5597|\n",
            "|electronics.smart...|samsung|521773470|     5597|\n",
            "|electronics.smart...|samsung|534538688|     5597|\n",
            "|electronics.smart...|samsung|513816945|     5597|\n",
            "|electronics.smart...|samsung|556736963|     5597|\n",
            "|electronics.smart...|samsung|551047678|     5597|\n",
            "|electronics.smart...|samsung|522742516|     5597|\n",
            "|electronics.smart...|samsung|512819219|     5597|\n",
            "|electronics.smart...|samsung|541760697|     5597|\n",
            "|electronics.smart...|samsung|556703332|     5597|\n",
            "|electronics.smart...|samsung|533902624|     5597|\n",
            "|electronics.smart...|samsung|540810781|     5597|\n",
            "|electronics.smart...|samsung|496811694|     5597|\n",
            "+--------------------+-------+---------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:55:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "23/11/13 21:56:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
            "[Stage 39:================================>                         (5 + 4) / 9]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------------+---------+---------+\n",
            "|       category_code|       brand|  user_id|max_count|\n",
            "+--------------------+------------+---------+---------+\n",
            "|                    |    elkitorg|518334158|        1|\n",
            "|                    |     bioline|539320069|        1|\n",
            "|                    |      casato|570455936|        1|\n",
            "|                    |     bioline|518049639|        1|\n",
            "|                    |        dabo|565727446|        1|\n",
            "|                    |     bioline|518921498|        1|\n",
            "|apparel.shoes.bal...|       baden|516497044|        1|\n",
            "|                    |   samsonite|577452466|        1|\n",
            "|                    |      aufine|515906876|        1|\n",
            "|                    |   samsonite|515986787|        1|\n",
            "|                    |    ecocraft|512432515|        1|\n",
            "|                    |   samsonite|522819804|        1|\n",
            "|                    |       leeco|545656741|        1|\n",
            "|                    |   samsonite|535729498|        1|\n",
            "|                    |    ecocraft|520451797|        1|\n",
            "|construction.tool...|       paton|514936876|        1|\n",
            "|                    |     bergamo|513698910|        1|\n",
            "|construction.tool...|       paton|530494893|        1|\n",
            "|                    |fantom-press|576283914|        1|\n",
            "|furniture.kitchen...|     everflo|518643264|        1|\n",
            "+--------------------+------------+---------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"Most_Engaged_Users\").getOrCreate()\n",
        "\n",
        "# Assuming 'orc_data' is your existing Spark DataFrame\n",
        "\n",
        "# Group by 'user_id', 'category_code', 'brand' and count interactions\n",
        "user_category_brand_interaction_count = cleaned_data.groupBy('user_id', 'category_code', 'brand').count()\n",
        "\n",
        "# Find the maximum count for each category and brand\n",
        "max_interactions_per_category_brand = user_category_brand_interaction_count.groupBy('category_code', 'brand') \\\n",
        "    .agg(max('count').alias('max_count'))\n",
        "\n",
        "# Join to find the most engaged users for each category and brand\n",
        "most_engaged_users = user_category_brand_interaction_count.join(max_interactions_per_category_brand,\n",
        "                                                               on=['category_code', 'brand'], how='inner')\n",
        "\n",
        "# Show the most engaged users within each category and brand in descending order of interaction counts\n",
        "print(most_engaged_users.select('category_code', 'brand', 'user_id', 'max_count') \\\n",
        "    .orderBy('max_count', ascending=False).show())\n",
        "print(most_engaged_users.select('category_code', 'brand', 'user_id', 'max_count') \\\n",
        "    .orderBy('max_count', ascending=True).show())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22BCi2BUKu3X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlJ-ev7UTEeG"
      },
      "source": [
        "#### Price Sensitivity within Categories: Evaluate user interactions with varying price ranges within different categories. This could reveal if users tend to engage more with specific price ranges or if certain categories are associated with higher-priced items.\n",
        "##### This code will group the data by 'category_code' and calculate the average, maximum, and minimum prices within each category. It provides insights into how users interact with varying price ranges within different categories, offering an understanding of price sensitivity across categories. Adjustments or further analysis can be performed based on your specific requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "mcmId51lPBum",
        "outputId": "52393841-51f1-47d9-ac83-0651aafa7789"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/11/13 23:36:51 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming 'cleaned_data' DataFrame is available and 'avg_prices' calculation is already done\n",
        "spark = SparkSession.builder.appName(\"Average\").getOrCreate()\n",
        "\n",
        "price_sensitivity = cleaned_data.groupBy('category_code').agg(\n",
        "    avg('price').alias('average_price'),\n",
        "    max('price').alias('max_price'),\n",
        "    min('price').alias('min_price')\n",
        ")\n",
        "\n",
        "# Get top 10 categories by average price\n",
        "top_10_avg_price_categories = price_sensitivity.orderBy(desc('average_price')).limit(10).toPandas()\n",
        "\n",
        "# Collect data for plotting\n",
        "top_10_categories = top_10_avg_price_categories['category_code']\n",
        "top_10_avg_prices = top_10_avg_price_categories['average_price']\n",
        "top_10_max_prices = top_10_avg_price_categories['max_price']\n",
        "top_10_min_prices = top_10_avg_price_categories['min_price']\n",
        "\n",
        "# Creating a line plot for average prices per category for top 10 categories\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(top_10_categories, top_10_avg_prices, marker='o', linestyle='-', color='green', label='Average Price')\n",
        "plt.plot(top_10_categories, top_10_max_prices, marker='o', linestyle='-', color='red', label='Max Price')\n",
        "plt.plot(top_10_categories, top_10_min_prices, marker='o', linestyle='-', color='blue', label='Min Price')\n",
        "\n",
        "plt.xlabel('Category Code')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Price Sensitivity for Top 10 Categories')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Save the top 10 categories to a CSV\n",
        "top_10_avg_price_categories.to_csv('spark_output/top_10_categories_prices.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cyaQoedTiaP",
        "outputId": "8934f09e-758d-42e6-8fc9-612ea1cfe125"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/11/13 22:56:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
            "[Stage 46:=====================================================>(782 + 1) / 783]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+-----------------+\n",
            "|        category_id|       category_code|interaction_count|\n",
            "+-------------------+--------------------+-----------------+\n",
            "|2053013555631882655|electronics.smart...|         28833250|\n",
            "|2053013553559896355|                    |          5294285|\n",
            "|2053013558920217191|  computers.notebook|          3394767|\n",
            "|2053013554415534427|electronics.video.tv|          3374747|\n",
            "|2053013554658804075|electronics.audio...|          3007758|\n",
            "|2053013563810775923|appliances.kitche...|          2329638|\n",
            "|2053013565983425517|appliances.enviro...|          2328665|\n",
            "|2053013563651392361|                    |          2303605|\n",
            "|2053013553341792533|  electronics.clocks|          1882651|\n",
            "|2053013561579406073|  electronics.clocks|          1630396|\n",
            "|2053013563911439225|appliances.kitche...|          1615724|\n",
            "|2053013563693335403|                    |          1439352|\n",
            "|2053013556168753601|                    |          1436253|\n",
            "|2053013563970159485|                    |          1291321|\n",
            "|2053013553853497655|                    |          1186732|\n",
            "|2053013557024391671|                    |          1174844|\n",
            "|2053013565639492569|       apparel.shoes|          1074051|\n",
            "|2053013553970938175|auto.accessories....|           982714|\n",
            "|2053013563173241677|                    |           930612|\n",
            "|2053013563584283495|                    |           767476|\n",
            "+-------------------+--------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import count, desc, col\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"Popular_Categories\").getOrCreate()\n",
        "\n",
        "## Group by 'category_id' and count interactions\n",
        "popular_categories = cleaned_data.groupBy('category_id','category_code').agg(count('*').alias('interaction_count'))\n",
        "\n",
        "# Sort by count in descending order\n",
        "popular_categories = popular_categories.orderBy(desc('interaction_count'))\n",
        "\n",
        "# Show the most frequently interacted categories\n",
        "popular_categories.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "bj_ncHTPTi9a",
        "outputId": "1cc904cf-db8a-4bc6-af28-6b12bab93718"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "local_popular_categories = popular_categories.limit(10).toPandas()\n",
        "local_popular_categories.to_csv('spark_output/top_10_categories.csv', index=False)\n",
        "\n",
        "\n",
        "# Plotting a pie chart using Matplotlib\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(local_popular_categories['interaction_count'], labels=local_popular_categories['category_code'], autopct='%1.1f%%')\n",
        "plt.title('Most Frequently Interacted Categories')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhaQR4pVVd6g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
